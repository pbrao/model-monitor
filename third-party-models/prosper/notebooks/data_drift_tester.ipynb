{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring data quality in third-party models from the AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "\n",
    "This notebook demonstrates how to configure an Amazon SageMaker Data Quality monitoring schedule for a pre-trained third-party model from the AWS Marketplace.\n",
    "\n",
    "**Contents:**\n",
    "- Pre-requisites\n",
    "- Step 1. Initial setup\n",
    "    - 1.1 [Import packages and modules](#section_1_1)\n",
    "    - 1.2 [Define global variables](#section_1_2)\n",
    "    - 1.3 [Uploading sample datasets to your S3 bucket](#section_1_3)\n",
    "- Step 2. Create and deploy the model endpoint with data capture\n",
    "    - 2.1 [Create the model](#section_2_1)\n",
    "    - 2.2 [Create the endpoint configuration with DataCapture](#section_2_2)\n",
    "    - 2.3 [Create the model endpoint](#section_2_3)\n",
    "    - 2.4 [Periodically check if the model's endpoint has changed from 'Creating' to 'InService'](#section_2_4)\n",
    "- Step 3. Create a baselining job to suggest a set of baseline constraints\n",
    "    - 3.1 [Create baselining job](#section_3_1)\n",
    "    - 3.2 [Periodically check if the baseline processing job has changed from 'InProgress' to 'Completed'](#section_3_2)\n",
    "- Step 4. Setup a monitoring schedule to monitor the data captured for the model's endpoint\n",
    "    - 4.1 [Create a monitoring schedule](#section_4_1)\n",
    "- Step 5. Invoking the inference endpoint with anomalous data\n",
    "    - 5.1 [Initialize a Predictor to make prediction requests to the model's endpoint](#section_5_1)\n",
    "    - 5.2 [Create a data quality constraint violations](#section_5_2)\n",
    "\n",
    "\n",
    "**Pre-requisites**\n",
    "\n",
    "This sample notebook requires a subscription to the [Propensity-Planning to Buy a House](https://aws.amazon.com/marketplace/pp/prodview-vzofptk4lnxii) model, a pre-trained machine learning model package from AWS Marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_1_1></a>\n",
    "#### 1.1 Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import session\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_1_2></a>\n",
    "#### 1.2 Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution role for the notebook instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# Stores configuration state and allows you to create service clients and resources\n",
    "session = session.Session()\n",
    "\n",
    "# Create a low-level client representing the Amazon S3 service\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Create a low-level client representing the Amazon SageMaker service\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# Create a low-level client representing the Amazon SageMaker Runtime\n",
    "smr_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3\n",
    "BUCKET = session.default_bucket() # Update as needed\n",
    "PREFIX = 'third-party-model-seller-name' # Update as needed\n",
    "\n",
    "DATASETS = ['train.csv', 'datadrift.csv']\n",
    "\n",
    "S3_DATA_CAPTURE_URI = 's3://{}/{}/datacapture'.format(BUCKET, PREFIX)\n",
    "S3_BASELINE_DATASET_URI = 's3://{}/{}/train/{}'.format(BUCKET, PREFIX, TRAINING_KEYS[0])\n",
    "S3_BASELINE_ANALYSIS_RESULTS_URI = 's3://{}/{}/baselining'.format(BUCKET, PREFIX)\n",
    "S3_DATA_QUALITY_RPT_URI = 's3://{}/{}/reports'.format(BUCKET, PREFIX)\n",
    "\n",
    "# Model\n",
    "MODEL_PACKAGE_ARN = 'arn:aws:sagemaker:us-east-1:865070037744:model-package/planning-to-buy-house-basic-28fcb3ca751705854a7171b255d8ef43'  # Update as needed\n",
    "MODEL_NAME = 'third-party-model-2'\n",
    "MODEL_ENDPOINT = 'third-party-model-endpoint-2'\n",
    "MODEL_ENDPOINT_CONFIG = 'third-party-model-endpoint-config-2'\n",
    "MODEL_BASELINE_JOB = 'third-party-model-baseline-job-2'\n",
    "MODEL_MONITOR_SCHEDULE_NAME = 'third-party-model-data-quality-schedule-2'\n",
    "MODEL_MONITOR_INSTANCE_TYPE = 'ml.m4.xlarge'\n",
    "MODEL_INFERENCE_INSTANCE_TYPE = 'ml.m4.xlarge'\n",
    "MODEL_INSTANCE_COUNT = 1\n",
    "\n",
    "# Training and testing dataset url path\n",
    "TRAINING_DATASET_URI = \"https://raw.githubusercontent.com/william-screen/model-monitor/main/third-party-models/prosper/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_1_3></a>\n",
    "#### 1.3 Uploading sample datasets to your S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training datasets for this demo\n",
    "for file_name in DATASETS:\n",
    "   \n",
    "    dataset = '{}/{}'.format(TRAINING_DATASET_URI, file_name)\n",
    "\n",
    "    # Sends a GET request to the specified url\n",
    "    response = requests.get(dataset, stream=True)\n",
    "\n",
    "    # S3 folder prefix and key\n",
    "    key = '{0}/train/{1}'.format(PREFIX, file_name)\n",
    "\n",
    "    # Upload data to this sessions default S3 bucket\n",
    "    response = s3_client.put_object(Body = response.content,\n",
    "                         Bucket = BUCKET,\n",
    "                         Key = key,\n",
    "                         ContentType = 'text/csv')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_1></a>\n",
    "#### 2.1 Create the model\n",
    "\n",
    "Creates a model in Amazon SageMaker from a model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, model_package_name, execution_role):\n",
    "    '''\n",
    "    Creates a model in Amazon SageMaker from a model package\n",
    "\n",
    "        Parameters:\n",
    "            model_name (str): The name of the new model\n",
    "            model_package_name (str): The name or ARN of the model package to use\n",
    "            execution_role (str): The ARN of the IAM role that Amazon SageMaker can assume\n",
    "\n",
    "        Returns:\n",
    "            response (str): The ARN of the model created in Amazon SageMaker\n",
    "    '''    \n",
    "    \n",
    "    # PrimaryContainer parameter\n",
    "    model_container_params = { \n",
    "        \"ModelPackageName\": model_package_name\n",
    "    }\n",
    "    \n",
    "    # Creates a model and returns the ModelArn\n",
    "    response = sm_client.create_model(\n",
    "        ModelName = model_name,\n",
    "        PrimaryContainer = model_container_params,\n",
    "        ExecutionRoleArn = execution_role,\n",
    "        EnableNetworkIsolation = True)\n",
    "    \n",
    "    # Get the ARN\n",
    "    response = response['ModelArn']    \n",
    "    \n",
    "    # Return\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to create the model\n",
    "model_arn = create_model(MODEL_NAME, MODEL_PACKAGE_ARN, role)\n",
    "print('>> The ARN of the model is: {}'.format(model_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_2></a>\n",
    "#### 2.2 Create the endpoint configuration with DataCapture\n",
    "\n",
    "Creates an endpoint configuration that Amazon SageMaker hosting services uses to deploy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_endpoint_config(enpoint_config_name, model_name, s3_data_catpure_uri, int_sampling_pct=100):\n",
    "    '''\n",
    "    Creates an endpoint configuration that Amazon SageMaker hosting services uses to deploy models.\n",
    "\n",
    "        Parameters:\n",
    "            enpoint_config_name (str): The name of the endpoint configuration\n",
    "            model_name (str): The name of the new model \n",
    "            s3_data_catpure_uri (str): S3 URI for datacapture data\n",
    "            int_sampling_pct (int): The amount of data to sample when the app has just started\n",
    "\n",
    "        Returns:\n",
    "            response (str): The ARN of the endpoint configuration\n",
    "    '''\n",
    "\n",
    "    # Describes the resources that you want Amazon SageMaker to provision\n",
    "    product_variant_params = {\n",
    "        'VariantName': 'AllTraffic',\n",
    "        'ModelName': model_name,\n",
    "        'InitialInstanceCount': MODEL_INSTANCE_COUNT,\n",
    "        'InstanceType': MODEL_INFERENCE_INSTANCE_TYPE\n",
    "    }\n",
    "\n",
    "    # Specifies the configuration of your endpoint for model monitor data capture.\n",
    "    data_capture_params = {   \n",
    "        'EnableCapture': True,\n",
    "        'InitialSamplingPercentage': int_sampling_pct,\n",
    "        'DestinationS3Uri': s3_data_catpure_uri,\n",
    "        'CaptureOptions': [\n",
    "            {\n",
    "                'CaptureMode': 'Input'\n",
    "            },\n",
    "            {\n",
    "                'CaptureMode': 'Output'\n",
    "            }        \n",
    "        ],\n",
    "        'CaptureContentTypeHeader': {\n",
    "            'CsvContentTypes': ['text/csv']\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    # Creates an endpoint configuration and returns the EndpointConfigArn    \n",
    "    response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName = enpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            product_variant_params\n",
    "        ],\n",
    "        DataCaptureConfig=data_capture_params\n",
    "    )\n",
    "    \n",
    "    # Get the ARN\n",
    "    response = response['EndpointConfigArn']\n",
    "    \n",
    "    # Return\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to create the endpoint config\n",
    "endpoint_config_arn = create_model_endpoint_config(MODEL_ENDPOINT_CONFIG, MODEL_NAME, S3_DATA_CAPTURE_URI)\n",
    "print('>> The ARN of the endpoint config is: {}'.format(endpoint_config_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_3></a>\n",
    "#### 2.3 Create the model endpoint\n",
    "\n",
    "Creates an endpoint using the endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_endpoint(enpoint_name, enpoint_config_name):\n",
    "    '''\n",
    "    Creates an endpoint using the endpoint configuration\n",
    "\n",
    "        Parameters:\n",
    "            enpoint_name (str): The name of the endpoint\n",
    "            enpoint_config_name (str): The name of the endpoint configuration\n",
    "\n",
    "        Returns:\n",
    "            response (str): The ARN of the endpoint\n",
    "    '''    \n",
    "    \n",
    "    # Creates an endpoint and returns the EndpointArn  \n",
    "    response = sm_client.create_endpoint(\n",
    "        EndpointName = enpoint_name,\n",
    "        EndpointConfigName = enpoint_config_name\n",
    "    )\n",
    "    \n",
    "    # Get the ARN\n",
    "    response = response['EndpointArn']\n",
    "    \n",
    "    # Return\n",
    "    return response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to create the endpoint\n",
    "endpoint_arn = create_model_endpoint(MODEL_ENDPOINT, MODEL_ENDPOINT_CONFIG)\n",
    "print('>> The ARN of the endpoint is: {}'.format(endpoint_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_4></a>\n",
    "#### 2.4 Periodically check if the model's endpoint has changed from 'Creating' to 'InService'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize\n",
    "model_endpoint_status = None\n",
    "\n",
    "# Get the model endpoint status descriptors\n",
    "response = sm_client.describe_endpoint(\n",
    "    EndpointName=MODEL_ENDPOINT\n",
    ")\n",
    "\n",
    "# Set the Endpoint Status value\n",
    "model_endpoint_status = response['EndpointStatus']\n",
    "\n",
    "# Check for status updates every 45 seconds\n",
    "while model_endpoint_status == 'Creating':\n",
    "    \n",
    "    # Pause execution for 45 seconds\n",
    "    time.sleep(45)\n",
    "    \n",
    "    # Get the model endpoint status descriptors\n",
    "    response = sm_client.describe_endpoint(\n",
    "        EndpointName=MODEL_ENDPOINT\n",
    "    )\n",
    "\n",
    "    # Set the Endpoint Status value\n",
    "    model_endpoint_status = response['EndpointStatus']\n",
    "    \n",
    "    # Print the current status of model endpoint\n",
    "    print('>> The current status of model endpoint \"{0}\" is {1}'.format(MODEL_ENDPOINT, model_endpoint_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_3_1></a>\n",
    "#### 3.1 Create a baselining job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baselining_job(job_name, wait_for_job_finish=False, show_logs=False):\n",
    "    '''\n",
    "    SageMaker to suggest a set of baseline constraints and generate descriptive statistics \n",
    "    (constraint_violations.json and statistics.json) based on the baseline training dataset\n",
    "\n",
    "        Parameters:\n",
    "            job_name (str): Name of processing job\n",
    "            wait_for_job_finish (bool): Whether the call should wait until the job completes\n",
    "            show_logs (bool): Whether to show the logs produced by the job\n",
    "\n",
    "        Returns:\n",
    "            default_model_monitor (ProcessingJob): The ProcessingJob object representing the baselining job.\n",
    "            job_name (str): job_name with appended timestamp.\n",
    "    '''  \n",
    "\n",
    "    # Initializes a Monitor instance\n",
    "    default_model_monitor = DefaultModelMonitor(\n",
    "        role=role,\n",
    "        instance_count=MODEL_INSTANCE_COUNT,\n",
    "        instance_type=MODEL_MONITOR_INSTANCE_TYPE\n",
    "    )\n",
    "    \n",
    "    # Append timestamp to job name\n",
    "    job_name = '{}-{}'.format(job_name, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "    # Suggest baselines for use with Amazon SageMaker Model Monitoring Schedules\n",
    "    default_model_monitor.suggest_baseline(\n",
    "        job_name = job_name,\n",
    "        baseline_dataset=S3_BASELINE_DATASET_URI,\n",
    "        dataset_format=DatasetFormat.csv(header=True),\n",
    "        output_s3_uri=S3_BASELINE_ANALYSIS_RESULTS_URI,\n",
    "        wait=wait_for_job_finish,\n",
    "        logs=show_logs\n",
    "    )\n",
    "    \n",
    "    # Return    \n",
    "    return default_model_monitor, job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to create baseline job\n",
    "default_model_monitor, job_name = create_baselining_job(MODEL_BASELINE_JOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_3_2></a>\n",
    "#### 3.2 Periodically check if the baseline processing job has changed from 'InProgress' to 'Completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize\n",
    "processing_job_status = None\n",
    "\n",
    "# Get the Processing Job Status descriptors\n",
    "response = sm_client.describe_processing_job(\n",
    "    ProcessingJobName=job_name\n",
    ")\n",
    "\n",
    "# Set the Processing Job Status value\n",
    "processing_job_status = response['ProcessingJobStatus']\n",
    "\n",
    "# Check for status updates every 45 seconds\n",
    "while processing_job_status == 'InProgress':\n",
    "    \n",
    "    # Pause execution for 45 seconds\n",
    "    time.sleep(45)\n",
    "    \n",
    "    # Get the Processing Job Status descriptors\n",
    "    response = sm_client.describe_processing_job(\n",
    "        ProcessingJobName=job_name\n",
    "    )\n",
    "\n",
    "    # Set the Processing Job Status value\n",
    "    processing_job_status = response['ProcessingJobStatus']\n",
    "    \n",
    "    # Print the current status\n",
    "    print('>> The current status of processing_job \"{0}\" is {1}'.format(job_name, processing_job_status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_4_1></a>\n",
    "#### 4.1 Create a monitoring schedule\n",
    "\n",
    "Note: Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule your execution. You might see your execution start anywhere between the first ~20 minutes after the hour boundary (i.e. 00:00 â€“ 00:20). This is expected and done for load balancing on the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monitoring_schedule(default_model_monitor, monitor_schedule_name):\n",
    "    '''\n",
    "        Creates a schedule that regularly starts Amazon SageMaker Processing Jobs\n",
    "        to monitor the data captured for an Amazon SageMaker Endoint.\n",
    "\n",
    "        Parameters:\n",
    "            default_model_monitor (ProcessingJob): The ProcessingJob object representing the baselining job.\n",
    "            monitor_schedule_name (str): Schedule name\n",
    "    '''  \n",
    "    \n",
    "    default_model_monitor.create_monitoring_schedule(\n",
    "        monitor_schedule_name = monitor_schedule_name,\n",
    "        endpoint_input = MODEL_ENDPOINT,\n",
    "        output_s3_uri = S3_DATA_QUALITY_RPT_URI,\n",
    "        statistics = default_model_monitor.baseline_statistics(),\n",
    "        constraints = default_model_monitor.suggested_constraints(),\n",
    "        schedule_cron_expression = CronExpressionGenerator.hourly()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to create monitoring schedule\n",
    "create_monitoring_schedule(default_model_monitor, MODEL_MONITOR_SCHEDULE_NAME)\n",
    "\n",
    "# Allow time for processing\n",
    "time.sleep(30)\n",
    "\n",
    "# Print the current status\n",
    "monitor_schedule_details = default_model_monitor.describe_schedule()['MonitoringScheduleStatus']\n",
    "print('>> The current status of monitoring schedule \"{0}\" is {1}'.format(MODEL_MONITOR_SCHEDULE_NAME, monitor_schedule_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_5_1></a>\n",
    "#### 5.1 Initialize a Predictor\n",
    "\n",
    "Make prediction requests to the model's endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor endpoint\n",
    "predictor = Predictor(endpoint_name=MODEL_ENDPOINT, \n",
    "                      sagemaker_session=None, \n",
    "                      serializer=CSVSerializer())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, delay=0.5):\n",
    "   \n",
    "    # Defensive coding\n",
    "    if(len(sample) > 0):    \n",
    "\n",
    "        # Invoke the model's inference endpoint\n",
    "        response = predictor.predict(data=sample)\n",
    "\n",
    "        # Decode bytes to string\n",
    "        response = response.decode('utf-8')\n",
    "        \n",
    "        # Suspends execution for # milliseconds\n",
    "        time.sleep(delay)        \n",
    "\n",
    "        # Return \n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_5_2></a>\n",
    "#### 5.2 Create a data quality constraint violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datadrift dataset key name\n",
    "key = '{0}/train/{1}'.format(PREFIX, DATASETS[1])\n",
    "\n",
    "# Download from S3\n",
    "datadrift_file_obj = s3_client.get_object(Bucket=BUCKET, Key=key)\n",
    "\n",
    "# Save to in-memory binary stream since file is relatively small (< 1 Mb)\n",
    "datadrift_file_buf = io.BytesIO(datadrift_file_obj['Body'].read())\n",
    "\n",
    "# Convert to Dataframe\n",
    "df = pd.read_csv(datadrift_file_buf, header=None)\n",
    "\n",
    "# Convert dataframe samples to list\n",
    "samples = df.values.tolist()\n",
    "\n",
    "# Invoke real-time inference endpoint \n",
    "for index, sample in enumerate(samples):\n",
    "\n",
    "    # Removes the open/close bracket from string -- not required\n",
    "    #sample = str(sample)[0:-1] \n",
    "    \n",
    "    # Get inference response\n",
    "    response = predict(sample)\n",
    "    \n",
    "    # Display the model's prediction probability\n",
    "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All set\n",
    "\n",
    "Now that the monitoring schedule has been created and we've generated some sample anamolous data to cause data drift detection, please return to the Amazon SageMaker Studio to checkout the Monitoring Job Details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Step 1.\n",
    "print('Stopping monitoring schedule...')\n",
    "!aws sagemaker stop-monitoring-schedule --monitoring-schedule-name 'third-party-model-data-quality-schedule-2'\n",
    "time.sleep(30) # allow time for processing\n",
    "!aws sagemaker list-monitoring-schedules --endpoint-name 'third-party-model-endpoint-2'\n",
    "\n",
    "# Step 2.\n",
    "print('Deleting monitoring schedule...')\n",
    "!aws sagemaker delete-monitoring-schedule --monitoring-schedule-name 'third-party-model-data-quality-schedule-2'\n",
    "time.sleep(30) # allow time for processing\n",
    "!aws sagemaker list-monitoring-schedules --endpoint-name 'third-party-model-endpoint'\n",
    "\n",
    "# Step 3.\n",
    "print('Deleting model endpoint...')\n",
    "!aws sagemaker delete-endpoint --endpoint-name 'third-party-model-endpoint-2'\n",
    "time.sleep(30) # allow time for processing\n",
    "!aws sagemaker list-endpoints --name-contains 'third-party-model-endpoint-2'\n",
    "\n",
    "# Step 4.\n",
    "print('Deleting model endpoint config...')\n",
    "!aws sagemaker delete-endpoint-config --endpoint-config-name 'third-party-model-endpoint-config-2'\n",
    "time.sleep(30) # allow time for processing\n",
    "!aws sagemaker list-endpoint-configs --name-contains 'third-party-model-endpoint-config-2'\n",
    "\n",
    "# Step 5.\n",
    "print('Deleting model...')\n",
    "!aws sagemaker delete-model --model-name 'third-party-model-2'\n",
    "time.sleep(30) # allow time for processing\n",
    "!aws sagemaker list-models --name-contains 'third-party-model-2'\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
