{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring data quality in third-party models from the AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "A typical third-party model usage journey includes finding a model that works for you, you do a deep evaluation using your own ground truth dataset, and then deploy it in production. If the statistical nature of the data that your model receives while in production drifts away from the nature of the baseline data it was evaluated on, the model might begin to lose accuracy in its predictions. \n",
    "\n",
    "Amazon SageMaker's [Data quality monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html) automatically monitors machine learning (ML) models in production and notifies you when data quality issues arise.  Amazon SageMaker Model Monitor uses rules to detect data drift and alerts you when it happens. These alerts will help you understand whether you would need to re-evalute the ML model to see if it is still providing you the correct outputs. If it does not, you would need to request the third party seller to retrain and provide a new version of the AWS Marketplace model. \n",
    "\n",
    "In this notebook, you will learn how to perform Data Quality monitoring on a pre-trained third-party model from the AWS Marketplace.\n",
    "\n",
    "**Contents:**\n",
    "- Pre-requisites\n",
    "- Step 1. Initial setup\n",
    "    - 1.1 [Import packages and modules](#section_1_1)\n",
    "    - 1.2 [Uploading sample datasets to your S3 bucket](#section_1_3)\n",
    "- Step 2. Create and deploy the model endpoint with data capture\n",
    "    - 2.1 [Create the model](#section_2_1)\n",
    "    - 2.2 [Create the endpoint configuration with DataCapture](#section_2_2)\n",
    "    - 2.3 [Create the model endpoint](#section_2_3)\n",
    "    - 2.4 [Periodically check if the model's endpoint has changed from 'Creating' to 'InService'](#section_2_4)\n",
    "- Step 3. Create a baselining job to suggest a set of baseline constraints\n",
    "    - 3.1 [Create baselining job](#section_3_1)\n",
    "- Step 4. Setup a monitoring schedule to monitor the data captured for the model's endpoint\n",
    "    - 4.1 [Create a monitoring schedule](#section_4_1)\n",
    "- Step 5. Invoking the inference endpoint with anomalous data\n",
    "    - 5.1 [Initialize a Predictor to make prediction requests to the model's endpoint](#section_5_1)\n",
    "    - 5.2 [Create a data quality constraint violations](#section_5_2)\n",
    "- Step 6. Invoking the inference endpoint with anomalous data\n",
    "    - 6.1 [Visualize the model monitor results](#section_6_1)\n",
    "    - 6.2 [Run the SageMaker-Model-Monitor-Visualize.ipynb notebook](#section_6_2)\n",
    "\n",
    "**Pre-requisites**\n",
    "\n",
    "This notebook requires a subscription to the [Propensity-Planning to Buy a House](https://aws.amazon.com/marketplace/pp/prodview-vzofptk4lnxii) model, a pre-trained machine learning model package from AWS Marketplace.\n",
    "\n",
    "1. Open the [Propensity-Planning to Buy a House](https://aws.amazon.com/marketplace/pp/prodview-vzofptk4lnxii) model in your browser. \n",
    "\n",
    "2. To subscribe to the model package, follow these steps: \n",
    "  1. Review the information available on the product details page including **Support Terms** .\n",
    "  1. Click on **\"Continue to Subscribe\"**. You will now see the **\"Subscribe to this software\"** page. \n",
    "  1. Review **End User License Agreement** and **Pricing Terms**.\n",
    "  1. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA, pricing information and support terms.\n",
    "  1. Once you click on **Continue to configuration** button and then choose a region, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3.  Copy the Model Package ARN and replace its contents in following cell. \n",
    "  \n",
    " \n",
    "Note: \n",
    "Products with **Free Trials**, do not incur hourly software charges during free trial period, but AWS infrastructure charges still apply. Free Trials will automatically convert to a paid hourly subscription upon expiration. We have included steps below to cancel subscription at the end of this exercise. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_PACKAGE_ARN=''\n",
    "MODEL_PACKAGE_ARN = 'arn:aws:sagemaker:us-east-1:865070037744:model-package/planning-to-buy-house-basic-28fcb3ca751705854a7171b255d8ef43'  # Update as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_1_1></a>\n",
    "#### 1.1 Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import session\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution role for the notebook instance.\n",
    "role = get_execution_role()\n",
    "session = session.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "sm_client = boto3.client('sagemaker')\n",
    "smr_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3\n",
    "BUCKET = session.default_bucket() # Update as needed\n",
    "PREFIX = 'propensity-model-seller-name' # Update as needed\n",
    "\n",
    "\n",
    "S3_DATA_CAPTURE_URI = 's3://{}/{}/datacapture'.format(BUCKET, PREFIX)\n",
    "S3_BASELINE_DATASET_URI = 's3://{}/{}/train/{}'.format(BUCKET, PREFIX, 'baseline.csv')\n",
    "S3_BASELINE_ANALYSIS_RESULTS_URI = 's3://{}/{}/baselining'.format(BUCKET, PREFIX)\n",
    "S3_DATA_QUALITY_RPT_URI = 's3://{}/{}/reports'.format(BUCKET, PREFIX)\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = 'propensity-model'\n",
    "MODEL_ENDPOINT = 'propensity-model-endpoint'\n",
    "MODEL_ENDPOINT_CONFIG = 'propensity-model-endpoint-config'\n",
    "MODEL_BASELINE_JOB = 'propensity-model-baseline-job'\n",
    "MODEL_MONITOR_SCHEDULE_NAME = 'propensity-model-data-quality-schedule'\n",
    "MODEL_MONITOR_INSTANCE_TYPE = 'ml.m4.xlarge'\n",
    "MODEL_INFERENCE_INSTANCE_TYPE = 'ml.m4.xlarge'\n",
    "MODEL_INSTANCE_COUNT = 1\n",
    "MODEL_BASELINE_JOB_NAME = '{}-{}'.format(MODEL_BASELINE_JOB, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_1_3></a>\n",
    "#### 1.2 Uploading sample datasets to your S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline.csv and data_quality_drift.csv files are curated datasets I created by modifying the seller's [sample notebook](https://github.com/goprosper/prosper-sagemaker-basic-geo/blob/master/using_prosper_model_package_basic_geo.ipynb) to return high propensity and low propensity values (respectively) for generating a baseline_drift_check constraint violation.\n",
    "\n",
    "Additionally, the data_quality_drift.csv file contains some rows with anomolous data that are used to demonstrate data_type_check and completeness_check constraint violations.\n",
    "\n",
    "The baseline.csv file contains 29 columns and 301 rows with the first column as the target value (prediction)\n",
    "\n",
    "The data_quality_drift.csv file contains 28 columns and 200 rows and is designed to illustrate a degredation in data quality from the baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/baseline.csv', \"rb\") as f:\n",
    "    response=s3_client.upload_fileobj(f, BUCKET, '{}/train/{}'.format(PREFIX, 'baseline.csv'))\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data_quality_drift.csv', \"rb\") as f:\n",
    "    s3_client.upload_fileobj(f, BUCKET, '{}/train/{}'.format( PREFIX, 'data_quality_drift.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_1></a>\n",
    "#### 2.1 Create the model\n",
    "\n",
    "Creates a model in Amazon SageMaker from a model package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a deployable model for damage inspection model package.\n",
    "model = ModelPackage(role=role,\n",
    "                      model_package_arn=MODEL_PACKAGE_ARN,\n",
    "                      sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_2_2></a>\n",
    "#### 2.2 Deploy model while enabling DataCapture\n",
    "\n",
    "Creates an endpoint configuration that Amazon SageMaker hosting services uses to deploy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=S3_DATA_CAPTURE_URI,\n",
    "                        csv_content_types=[\"text/csv\"])\n",
    "\n",
    "#Deploy the model.\n",
    "predictor = model.deploy(1, MODEL_INFERENCE_INSTANCE_TYPE, endpoint_name=MODEL_ENDPOINT,data_capture_config=data_capture_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_3_1></a>\n",
    "#### 3.1 Create a baselining job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline calculations of statistics and constraints are needed as a standard against which data drift and other data quality issues can be detected. \n",
    "\n",
    "This job generates baseline statistics and suggests baseline constraints for the dataset and writes them to the output_s3_uri location that you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initializes a Monitor instance\n",
    "default_model_monitor = DefaultModelMonitor(role=role,\n",
    "                                            instance_count=MODEL_INSTANCE_COUNT,\n",
    "                                            instance_type=MODEL_MONITOR_INSTANCE_TYPE)\n",
    "\n",
    "# Suggest baselines for use with Amazon SageMaker Model Monitoring Schedules\n",
    "job = default_model_monitor.suggest_baseline(\n",
    "    job_name = MODEL_BASELINE_JOB_NAME,\n",
    "    baseline_dataset=S3_BASELINE_DATASET_URI,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=S3_BASELINE_ANALYSIS_RESULTS_URI,\n",
    "    wait=True,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_4_1></a>\n",
    "#### 4.1 Create a monitoring schedule\n",
    "\n",
    "In this step, you create a schedule that regularly starts Amazon SageMaker Processing Jobs to monitor the data captured for an Amazon SageMaker Endoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "    Even for an hourly schedule, Amazon SageMaker has a buffer period of 20 minutes to schedule your execution. You might see your execution start anywhere between the first ~20 minutes after the hour boundary (i.e. 00:00 – 00:20). This is expected and done for load balancing on the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name = MODEL_MONITOR_SCHEDULE_NAME,\n",
    "    endpoint_input = MODEL_ENDPOINT,\n",
    "    output_s3_uri = S3_DATA_QUALITY_RPT_URI,\n",
    "    statistics = default_model_monitor.baseline_statistics(),\n",
    "    constraints = default_model_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression = CronExpressionGenerator.hourly()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow time for processing\n",
    "time.sleep(30)\n",
    "\n",
    "# Print the current status\n",
    "monitor_schedule_details = default_model_monitor.describe_schedule()['MonitoringScheduleStatus']\n",
    "print('>> The current status of monitoring schedule \"{0}\" is {1}'.format(MODEL_MONITOR_SCHEDULE_NAME, monitor_schedule_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_5_1></a>\n",
    "#### 5.1 Initialize a Predictor\n",
    "\n",
    "Make prediction requests to the model's endpoint. The Predictor object is used to invoke the model's real-time inference endpoint to make predictions based on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor endpoint\n",
    "predictor = Predictor(endpoint_name=MODEL_ENDPOINT, \n",
    "                      sagemaker_session=None, \n",
    "                      serializer=CSVSerializer())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    if(len(sample) > 0):    \n",
    "        return predictor.predict(data=sample).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_5_2></a>\n",
    "#### 5.2 Create data quality constraint violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we'll generate a couple of constraint violations (data_type_check, completeness_check, and baseline_drift_check) for Amazon SageMaker Model Monitor to detect.\n",
    "\n",
    "Here's the structure of the data_quality_drift.csv file:\n",
    "\n",
    "- Rows 1-10:  Samples with negative floating point values (instead of positive integers) in the 3rd and 4th columns\n",
    "- Rows 11-20: Samples with missing values in the 2nd column\n",
    "- Rows 20-200: Samples that yield a low propensity prediction that deviates from the baseline.\n",
    "\n",
    "We'll use array slicing for accessing the anomolous sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataframe\n",
    "df = pd.read_csv('../data/data_quality_drift.csv', header=None, na_filter=False)\n",
    "\n",
    "# List values by column to maintain the column dtype\n",
    "samples = [df[x].values.tolist() for x in df.columns]\n",
    "\n",
    "# Use unpacking operator * to unzip the data\n",
    "samples = list(list(x) for x in zip(*samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll generate a data_type_check constraint violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke real-time inference endpoint \n",
    "for index, sample in enumerate(samples[0:10]):\n",
    "\n",
    "    # Get inference response\n",
    "    response = predict(sample)\n",
    "    time.sleep(0.5)\n",
    "    # Display the model's prediction probability\n",
    "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate a completeness_check constraint violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke real-time inference endpoint \n",
    "for index, sample in enumerate(samples[10:20]):\n",
    "\n",
    "    # Get inference response\n",
    "    response = predict(sample)\n",
    "    time.sleep(0.5)\n",
    "    # Display the model's prediction probability\n",
    "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll generate a baseline_drift_check constraint violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke real-time inference endpoint \n",
    "for index, sample in enumerate(samples[20:]):\n",
    "\n",
    "    # Get inference response\n",
    "    response = predict(sample)\n",
    "    time.sleep(0.5)\n",
    "    # Display the model's prediction probability\n",
    "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_6_1></a>\n",
    "#### 6.1 Visualize the model monitor results\n",
    "\n",
    "After the data drift monitoring job has run, go to the Model Monitoring tab, double-click the monitoring job to view the monitoring job details. The Monitoring status of ‘Issue found’ indicates that the monitor successfully detected one or more data quality constraint violations created by the data drift datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/s4-1-sm-studio-visualize-results.png\"\n",
    "    alt=\"Amazon Sagemaker Data Drift Monitoring\"\n",
    "    style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/s4-2-monitoring-job-report-details.png\"\n",
    "    alt=\"Amazon Sagemaker Model Job Report\"\n",
    "    style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section_6_2></a>\n",
    "#### 6.2 Run the SageMaker-Model-Monitor-Visualize.ipynb notebook\n",
    "\n",
    "To graphically visualize the distribution and the distribution statistics for all features, SakeMaker includes a pre-built notebook for viewing feature statistics.\n",
    "\n",
    "1. In the Monitoring Job Details tab, copy the full value for the Processing Job ARN to your clipboard\n",
    "2. Select the View Amazon SageMaker notebook link\n",
    "3. Select Import Notebook (in the upper-right section of the tab)\n",
    "4. Select Kernel: Python 3 (Data Science), then choose the Select button. (It may take a few minutes for the Kernel to start)\n",
    "5. After importing the SageMaker-Model-Monitor-Visualize.ipynb notebook, update the code cell that contains the variable processing_job_arn with the value from the Processing Job ARN in your clipboard.\n",
    "6. Run all cells in the notebook to review the execution and baseline details from the model monitoring processing job.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/s4-3-mm_visualize_inf_vs_baseline_stats-v2.png\"\n",
    "    alt=\"SageMaker Model Monitor Visualize notebook - Numerical Features\"\n",
    "    style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "Bar chart illustrating the statistical data quality deviation between the baseline data and the data drift dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/s4-3-mm_visualize_inf_vs_baseline_stats_chart-v2.png\"\n",
    "    alt=\"SageMaker Model Monitor Visualize notebook - Inference feature statistics plots\"\n",
    "    style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "Inference feature statistics plotted against baseline feature statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stopping monitoring schedule...')\n",
    "sm_client.stop_monitoring_schedule(MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME)\n",
    "time.sleep(30) # allow time for processing\n",
    "sm_client.delete_monitoring_schedule(MonitoringScheduleName=MODEL_MONITOR_SCHEDULE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(MODEL_ENDPOINT)\n",
    "model.sagemaker_session.delete_endpoint_config(MODEL_ENDPOINT_CONFIG)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you would need to cancel subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
