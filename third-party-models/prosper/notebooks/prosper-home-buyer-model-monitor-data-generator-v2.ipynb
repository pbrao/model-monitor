{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "prosper-home-buyer-model-monitor-data-generator.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6-b7QSZQQYu"
      },
      "source": [
        "import boto3\n",
        "from sagemaker import session\n",
        "\n",
        "from sagemaker.predictor import Predictor\n",
        "from sagemaker.serializers import CSVSerializer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import io\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhKqushNQQY0"
      },
      "source": [
        "#### Globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duJ9bEJTQQY3"
      },
      "source": [
        "# Session\n",
        "sm_session = session.Session(boto3.Session())\n",
        "\n",
        "# S3 client\n",
        "s3_client = boto3.client('s3')\n",
        "\n",
        "# S3 bucket\n",
        "bucket = 'sagemaker-demo-third-party-models'\n",
        "\n",
        "# Model provider name\n",
        "prefix = 'prosper'\n",
        "\n",
        "# Model endpoint name\n",
        "endpoint_name = 'third-party-model-endpoint'\n",
        "\n",
        "# Data files\n",
        "buyer_zip_code_features_data_file = 'train/sample_basic_zip.csv'\n",
        "zip_code_features_data_file = 'train/zip_features.csv'\n",
        "training_data_file = 'train/train.csv'\n",
        "\n",
        "# Total encoded zip classes\n",
        "num_encoded_zip_classes = 25\n",
        "\n",
        "# Zipcode cluster classes\n",
        "num_cluster_classes = 16\n",
        "\n",
        "# Zipcode division classes\n",
        "num_division_classes = 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGt3ec71QQY4"
      },
      "source": [
        "#### Loading data files from S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TyupSTFQQY4",
        "outputId": "0a97f026-ab2f-42fc-f500-ac071ed22eec"
      },
      "source": [
        "# Labels for data file\n",
        "cols = ['gender', 'age_range', 'household_income_range', 'zip_features']\n",
        "\n",
        "# Get sample_basic_zip\n",
        "key = '{}/{}'.format(prefix, buyer_zip_code_features_data_file)\n",
        "\n",
        "# Download from S3\n",
        "basic_zip_file_obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
        "\n",
        "# Save to in-memory binary stream since file is relatively small (< 1 Mb)\n",
        "basic_zip_buf = io.BytesIO(basic_zip_file_obj['Body'].read())\n",
        "\n",
        "# Convert to Dataframe\n",
        "basic_zip_df = pd.read_csv(basic_zip_buf, names=cols, encoding='utf-8')\n",
        "\n",
        "# Verify\n",
        "basic_zip_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age_range</th>\n",
              "      <th>household_income_range</th>\n",
              "      <th>zip_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>17011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>71923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>84095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>13905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>22032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  age_range  household_income_range  zip_features\n",
              "0       0          5                      10         17011\n",
              "1       1          7                      13         71923\n",
              "2       0          4                      21         84095\n",
              "3       1          7                       8         13905\n",
              "4       0          3                       4         22032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIluvA1yQQY5",
        "outputId": "6a68801f-1f78-4e25-c8f6-b4493c93b62e"
      },
      "source": [
        "# Get zip_features (file includes col headers)\n",
        "key = '{}/{}'.format(prefix, zip_code_features_data_file)\n",
        "\n",
        "# Download from S3\n",
        "zip_features_file_obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
        "\n",
        "# Save to in-memory binary stream since file is relatively small (< 1 Mb)\n",
        "zip_features_buf = io.BytesIO(zip_features_file_obj['Body'].read())\n",
        "\n",
        "# Convert to Dataframe\n",
        "zip_features_df = pd.read_csv(zip_features_buf, encoding='utf-8')\n",
        "\n",
        "# Verify\n",
        "zip_features_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zip_code</th>\n",
              "      <th>cluster</th>\n",
              "      <th>division</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1005</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1007</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1008</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   zip_code  cluster  division\n",
              "0      1001        3         0\n",
              "1      1002        4         0\n",
              "2      1005       14         0\n",
              "3      1007       14         0\n",
              "4      1008       14         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvStNAQRQQY5"
      },
      "source": [
        "#### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaqthEdpQQY6"
      },
      "source": [
        "def get_zip_code_features(zip_features_df, zip_code):\n",
        "\n",
        "    # Get the zip code features using a Dataframe query\n",
        "    zip_features = zip_features_df[(zip_features_df.zip_code == int(zip_code))]\n",
        "       \n",
        "    # If no match found, then create empty encoding list\n",
        "    result = np.zeros((np.add(num_cluster_classes, num_division_classes)), dtype=int)    \n",
        "\n",
        "    # Defensive coding\n",
        "    if(len(zip_features) > 0):\n",
        "\n",
        "        # Get matching feature values\n",
        "        cluster = zip_features['cluster'].values[0]\n",
        "        division = zip_features['division'].values[0]\n",
        "\n",
        "        # One-hot encode feature values\n",
        "        cluster_encoded = np.eye(num_cluster_classes, dtype=int)[cluster]\n",
        "        division_encoded = np.eye(num_division_classes, dtype=int)[division]\n",
        "\n",
        "        # Concatenate the encoded features\n",
        "        result = np.concatenate( (cluster_encoded, division_encoded) )\n",
        "           \n",
        "    # Return            \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt2WpOCOQQY6"
      },
      "source": [
        "def predict(sample, predictor=predictor, delay=0.5):\n",
        "   \n",
        "    # Defensive coding\n",
        "    if(len(sample) > 0):\n",
        "        \n",
        "        # Create predictor endpoint\n",
        "        predictor = Predictor(endpoint_name=endpoint_name, \n",
        "                              sagemaker_session=None, \n",
        "                              serializer=CSVSerializer())        \n",
        "\n",
        "        # Invoke the model's inference endpoint\n",
        "        response = predictor.predict(data=sample)\n",
        "\n",
        "        # Decode bytes to string\n",
        "        response = response.decode('utf-8')\n",
        "        \n",
        "        # Suspends execution for # milliseconds\n",
        "        time.sleep(delay)        \n",
        "\n",
        "        # Return \n",
        "        return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYKAAOxsQQY6"
      },
      "source": [
        "#### Create baseline training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCwPVgnbQQY7"
      },
      "source": [
        "# Labels for one-hot encoded zip data features: zip_feature_0 - zip_feature_24\n",
        "encoded_zip_feature_cols = np.array(['zip_feature_{}'.format(i) for i in range(0, num_encoded_zip_classes)])\n",
        "\n",
        "# Get list of one-hot encoded zip features based on zipcode\n",
        "encoded_zip_features = [get_zip_code_features(zip_features_df, zipcode) for zipcode in basic_zip_df['zip_features']]\n",
        "\n",
        "# Create dataframe for the encoded zip_features\n",
        "encoded_zip_features_df = pd.DataFrame(encoded_zip_features, columns=encoded_zip_feature_cols)\n",
        "\n",
        "# Concatenate the first three columns of the home buyers file with the encoded zip features\n",
        "df = pd.concat([basic_zip_df[['gender', 'age_range', 'household_income_range']], encoded_zip_features_df], axis=1)\n",
        "\n",
        "# Adding a placeholder target column as first column\n",
        "# I get a \"extra_column_check\" violation error without the target column\n",
        "# Can't find documentation as to why I need to include the additional column for a DataQuality monitoring job.\n",
        "# The addt'l col would make sense for a ModelQuality monitoring job -- will reach out to the SM MM devs for more info.\n",
        "# Seemingly, an error should be thrown if baseline columns are < or > inference cols, not if cols are equal length\n",
        "df.insert(loc=0, column='target', value=0.00)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFF5w5e9QQY7"
      },
      "source": [
        "# Load dataset into memory (since it is a relatively small dataset) \n",
        "data_stream = io.StringIO()\n",
        "df.to_csv(data_stream, sep=',', encoding='utf-8', index=False) #header=False\n",
        "\n",
        "# Get stream data from memory\n",
        "train_csv = data_stream.getvalue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaMY5lSyQQY7"
      },
      "source": [
        "# Upload to S3 bucket\n",
        "key = '{}/{}'.format(prefix, training_data_file)\n",
        "s3_client.put_object(Body=train_csv,\n",
        "                     Bucket=bucket, \n",
        "                     Key=key, \n",
        "                     ContentType='text/csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS6Z7rNXQQY7"
      },
      "source": [
        "#### Preprocess data for inference endpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc8ubXFiQQY8"
      },
      "source": [
        "# Select all columns except added 'target' for inference\n",
        "df = df.iloc[:, 1:]\n",
        "\n",
        "# Convert buyer zip_code samples to list\n",
        "samples = df.values.tolist()\n",
        "\n",
        "# Convert zip_code samples to list\n",
        "zip_samples = zip_features_df['zip_code'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnfPvV3JQQY8"
      },
      "source": [
        "#### Generate baseline data to trigger 'No Issues'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYVzQIq6QQY8",
        "outputId": "da9fb13c-b767-42f1-a611-713a49443481"
      },
      "source": [
        "# Replay the training dataset as sample inference data\n",
        "batch_size = 10\n",
        "\n",
        "# Invoke real-time inference endpoint using baseline data\n",
        "for index, sample in enumerate(samples[0:batch_size]):\n",
        "\n",
        "    # Removes the open/close bracket from string -- not required\n",
        "    sample = str(sample)[1:-1] \n",
        "    \n",
        "    # Get inference response\n",
        "    response = predict(sample)\n",
        "    \n",
        "    # Display the model's prediction probability\n",
        "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 0 >> Input: 0, 5, 10, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0: >> Prediction: 0.4805711507797241\n",
            "Sample 1 >> Input: 1, 7, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0: >> Prediction: 0.46936097741127014\n",
            "Sample 2 >> Input: 0, 4, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0: >> Prediction: 0.5250639915466309\n",
            "Sample 3 >> Input: 1, 7, 8, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0: >> Prediction: 0.46936097741127014\n",
            "Sample 4 >> Input: 0, 3, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0: >> Prediction: 0.5310230255126953\n",
            "Sample 5 >> Input: 1, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0: >> Prediction: 0.46936097741127014\n",
            "Sample 6 >> Input: 1, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0: >> Prediction: 0.49675580859184265\n",
            "Sample 7 >> Input: 1, 5, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0: >> Prediction: 0.49675580859184265\n",
            "Sample 8 >> Input: 1, 6, 22, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0: >> Prediction: 0.48939019441604614\n",
            "Sample 9 >> Input: 1, 6, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0: >> Prediction: 0.45879191160202026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB4GnOkGQQY9"
      },
      "source": [
        "#### Generate data to induce data quality constraint violations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jySj_KeVQQY9",
        "outputId": "18302045-50c3-459d-ac17-2ff4df09da8f"
      },
      "source": [
        "# Number of samples generated for the inference endpoint\n",
        "batch_size = 10\n",
        "\n",
        "# Set min/max ranges for 'gender', 'age_range', 'household_income_range'\n",
        "gender_min, gender_max = 0, 1\n",
        "age_range_min, age_range_max = 1, 6\n",
        "household_income_range_min, household_income_range_max = 0, 24\n",
        "\n",
        "# Let's create a 'data_type_check' data quality constraint violation by sending negative fractional values\n",
        "# instead of the expected positive integer values\n",
        "noise_factor = -0.5\n",
        "\n",
        "# Invoke real-time inference endpoint\n",
        "for index in range(batch_size):\n",
        "                \n",
        "    # Assign random values to each feature\n",
        "    gender = random.randint(gender_min, gender_max) * noise_factor\n",
        "    age_range = random.randint(age_range_min, age_range_max) * noise_factor\n",
        "    household_income_range = random.randint(household_income_range_min, household_income_range_max) * noise_factor\n",
        "\n",
        "    # Shuffle the zip code samples\n",
        "    random.shuffle(zip_samples)\n",
        "\n",
        "    # One-hot encode the random zipcode\n",
        "    zip_features = get_zip_code_features(zip_features_df, zip_samples[0]) # * noise_factor\n",
        "    zip_features = \",\".join(zip_features.astype(str))    \n",
        "\n",
        "    # Format request data as comma-delimited string\n",
        "    sample = f'{gender},{age_range},{household_income_range},{zip_features}'\n",
        "\n",
        "    # Get inference response\n",
        "    response = predict(sample)\n",
        "    \n",
        "    # Display the model's prediction probability\n",
        "    print('Sample {0} >> Input: {1}: >> Prediction: {2}'.format(index, sample, response))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample 0 >> Input: -0.0,-0.5,-5.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 1 >> Input: -0.0,-1.0,-8.5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 2 >> Input: -0.0,-2.0,-9.5,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 3 >> Input: -0.0,-1.0,-2.0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 4 >> Input: -0.5,-3.0,-0.0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 5 >> Input: -0.5,-2.5,-2.5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 6 >> Input: -0.0,-0.5,-3.0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1: >> Prediction: 0.5188708305358887\n",
            "Sample 7 >> Input: -0.5,-1.0,-7.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1: >> Prediction: 0.5188708305358887\n",
            "Sample 8 >> Input: -0.0,-1.5,-9.5,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0: >> Prediction: 0.5188708305358887\n",
            "Sample 9 >> Input: -0.0,-1.5,-7.0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0: >> Prediction: 0.5188708305358887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obW_OXqPQQY9"
      },
      "source": [
        "# Manully induce a completeness_check constraint violation:\n",
        "completeness_check_gender = ''\"\"',5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0'\n",
        "completeness_check_age = '0,'\"\"',0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0'\n",
        "completeness_check_hir = '0,1,'\"\"',0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0'\n",
        "\n",
        "# Uncomment and run cell for each feature\n",
        "# sample = completeness_check_gender\n",
        "# sample = completeness_check_age\n",
        "sample = completeness_check_hir\n",
        "\n",
        "# Get inference response\n",
        "response = predict(sample)\n",
        "\n",
        "# Display the model's prediction probability\n",
        "print('Sample >> Input: {0}: >> Prediction: {1}'.format(sample, response))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ze36JBqQQY-"
      },
      "source": [
        "#### Monitoring Schedule management"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6doDXmzQQY-"
      },
      "source": [
        "# !aws sagemaker describe-monitoring-schedule --monitoring-schedule-name 'third-party-model-data-quality-schedule'\n",
        "# !aws sagemaker list-monitoring-executions --monitoring-schedule-name 'third-party-model-data-quality-schedule'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ZCXqyAQQY-"
      },
      "source": [
        "#### Resource Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-dCIbmDQQY-"
      },
      "source": [
        "# Step 1.\n",
        "# print('Stopping monitoring schedule...')\n",
        "# !aws sagemaker stop-monitoring-schedule --monitoring-schedule-name 'third-party-model-data-quality-schedule'\n",
        "# time.sleep(30) # allow time for processing\n",
        "# !aws sagemaker list-monitoring-schedules --endpoint-name 'third-party-model-endpoint'\n",
        "\n",
        "# Step 2.\n",
        "# print('Deleting monitoring schedule...')\n",
        "# !aws sagemaker delete-monitoring-schedule --monitoring-schedule-name 'third-party-model-data-quality-schedule'\n",
        "# time.sleep(30) # allow time for processing\n",
        "# !aws sagemaker list-monitoring-schedules --endpoint-name 'third-party-model-endpoint'\n",
        "\n",
        "# Step 3.\n",
        "# print('Deleting model endpoint...')\n",
        "# !aws sagemaker delete-endpoint --endpoint-name 'third-party-model-endpoint'\n",
        "# time.sleep(30) # allow time for processing\n",
        "# !aws sagemaker list-endpoints --name-contains 'third-party-model-endpoint'\n",
        "\n",
        "# Step 4.\n",
        "# print('Deleting model endpoint config...')\n",
        "# !aws sagemaker delete-endpoint-config --endpoint-config-name 'third-party-model-endpoint-config'\n",
        "# time.sleep(30) # allow time for processing\n",
        "# !aws sagemaker list-endpoint-configs --name-contains 'third-party-model-endpoint-config'\n",
        "\n",
        "# Step 5.\n",
        "# print('Deleting model...')\n",
        "# !aws sagemaker delete-model --model-name 'third-party-model'\n",
        "# time.sleep(30) # allow time for processing\n",
        "# !aws sagemaker list-models --name-contains 'third-party-model'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}